{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 14:53:40.189413: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-27 14:53:41.175695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-27 14:53:41.175767: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-27 14:53:41.317383: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-27 14:53:44.756689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-27 14:53:44.756995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-27 14:53:44.757026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##import packages\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "from keras.backend import clear_session\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import numpy as np\n",
    "import yaml\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading the path\n",
    "dir_path = './data/'\n",
    "files_list = os.listdir(dir_path + os.sep)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 418\n"
     ]
    }
   ],
   "source": [
    "#question list\n",
    "questions = list()\n",
    "answers = list() #answers list from yml file\n",
    "\n",
    "for filepath in files_list:#opens all yml file, read it, take the questions and answers from it. \n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(stream)##load yml file\n",
    "    conversations = docs['conversations'] ##take conversations key part\n",
    "    for con in conversations:\n",
    "        if len( con ) > 2 : ##if the length of con means under the conversation part all the text's len if >2 \n",
    "            questions.append(con[0]) ##the frist part will be added\n",
    "            replies = con[ 1 : ] ##after the first part added, the replies are added.\n",
    "            ans = '' ##ans has empty list\n",
    "            for rep in replies: ##take rep from replies list\n",
    "                ans += ' ' + rep ##adding all text and make sentenses\n",
    "            answers.append( ans ) ##append it in answers list\n",
    "        elif len( con )> 1: ##if the con has more than 1 length\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])\n",
    "\n",
    "answers_with_tags = list() ##tags appendings\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "\n",
    "answers = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( ' ' + answers_with_tags[i] + ' ' )\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()##convert text to sequence of integers \n",
    "tokenizer.fit_on_texts( questions + answers )##fit it \n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1 ##check the sequence of integers length\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vocab = []\n",
    "for word in tokenizer.word_index: ##then take the integer index of word which mostly common and maximum\n",
    "  vocab.append(word)##append it in vocab\n",
    "\n",
    "def tokenize(sentences):##tokenize function\n",
    "  tokens_list = []##tokens_list\n",
    "  vocabulary = []##vocabulary_list\n",
    "  for sentence in sentences:\n",
    "    sentence = sentence.lower()##convert each of the letter into lower\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)##replaced specific pattern to the sentence \n",
    "    tokens = sentence.split() ##split the words from sentence\n",
    "    vocabulary += tokens##added the vocabulary\n",
    "    tokens_list.append(tokens)##append it into the tokens_list\n",
    "  return tokens_list, vocabulary\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 9) 9\n",
      "(111, 26) 26\n"
     ]
    }
   ],
   "source": [
    "tokenized_questions = tokenizer.texts_to_sequences( questions )##again convert into integer sequences\n",
    "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "print(encoder_input_data.shape, maxlen_questions)\n",
    "     \n",
    "\n",
    "\n",
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 26, 418)\n"
     ]
    }
   ],
   "source": [
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )##convert into 2d Numpy array\n",
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )##convert class vectors or integer into binary matrix\n",
    "decoder_output_data = np.array( onehot_answers )\n",
    "print( decoder_output_data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 14:54:24.806082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-27 14:54:24.806823: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-27 14:54:24.806950: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hrithik-Lenovo-ideapad-320-15ISK): /proc/driver/nvidia/version does not exist\n",
      "2022-12-27 14:54:24.808532: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 9, 200)       83600       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 26, 200)      83600       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 26, 200),    320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 26, 418)      84018       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 892,818\n",
      "Trainable params: 892,818\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)##nlp related work\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 13s 78ms/step - loss: 2.0721\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 1.8728\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 1.7976\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 1.7631\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 1.7205\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 1.6704\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 1.6097\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 1.5442\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 1.4745\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 1.4030\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 1.3305\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 1.2553\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 1.1739\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 1.0885\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 1.0072\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.9226\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.8476\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 2s 99ms/step - loss: 0.7748\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.7019\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.6303\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.5692\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.5018\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.4448\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.3898\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.3451\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.3027\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.2687\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 2s 90ms/step - loss: 0.2380\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2092\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.1853\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.1665\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.1485\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.1321\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.1181\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.1075\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.0980\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0894\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0820\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0750\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0693\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.0639\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0607\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0554\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0509\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0477\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0446\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0415\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0391\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.0374\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0366\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0343\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0322\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0304\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0290\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0276\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0279\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0261\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.0242\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0229\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0222\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0214\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0206\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0201\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0195\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.0189\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0180\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0173\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0172\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0166\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0170\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0158\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0152\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0150\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0143\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0142\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0151\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0141\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0132\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0129\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0126\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0119\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.0118\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0114\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0115\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0111\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0108\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0106\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0103\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0105\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.0113\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0106\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0098\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0097\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0099\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0095\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0091\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0088\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0091\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0085\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0094\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0086\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.0085\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0085\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0081\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0080\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.0078\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0083\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0077\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 2s 97ms/step - loss: 0.0075\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0074\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0073\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0073\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0072\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.0071\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0071\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0069\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.0071\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0074\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.0069\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0070\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.0068\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0064\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.0065\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0064\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0064\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0063\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0061\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0063\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0070\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.0065\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0064\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.0060\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.0064\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 2s 97ms/step - loss: 0.0061\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 0.0058\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.0059\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 2s 106ms/step - loss: 0.0060\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 2s 106ms/step - loss: 0.0066\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 2s 106ms/step - loss: 0.0061\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.0055\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 0.0058\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 0.0057\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.0066\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 0.0062\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.0055\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 2s 106ms/step - loss: 0.0054\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.0052\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0052\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.0054\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0051\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0053\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.0055\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0056\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.0052\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0050\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.0049\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0052\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 0.0049\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0050\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.0049\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0048\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 2s 104ms/step - loss: 0.0049\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.0049\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 0.0053\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.0051\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 2s 106ms/step - loss: 0.0050\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 0.0049\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 0.0055\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 3s 116ms/step - loss: 0.0050\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 0.0057\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 2s 104ms/step - loss: 0.0053\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 3s 106ms/step - loss: 0.0049\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 0.0045\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 0.0046\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 4s 154ms/step - loss: 0.0048\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.0047\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0045\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.0045\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0045\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.0046\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.0044\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 0.0046\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 2s 104ms/step - loss: 0.0042\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.0045\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 2s 104ms/step - loss: 0.0043\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0045\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.0045\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 0.0046\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.0045\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 2s 103ms/step - loss: 0.0043\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.0043\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.0047\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 2s 104ms/step - loss: 0.0050\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 2s 104ms/step - loss: 0.0045\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 2s 107ms/step - loss: 0.0044\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0044\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.0042\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 2s 106ms/step - loss: 0.0045\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.0043\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=5, epochs=200 ,verbose=1) \n",
    "model.save( 'model.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    \n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def str_to_tokens( sentence : str ):\n",
    "\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "  \n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 26) for input KerasTensor(type_spec=TensorSpec(shape=(None, 26), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      " software is the field of science which concerns itself with building hardware and software that replicates the functions of the human mind software software software that is\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      " software work on all operating systems including windows linux and mac os software software software will you software me software software that there is software that i\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      " software do that alwasy smiling yes i am there tell me software software software software that there is a resemblance between us software software software that on\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      " software runs on all operating systems linux and mac os software software software will you i am listening software software software that on all there is software\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m decoded_translation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m stop_condition :\n\u001b[0;32m---> 10\u001b[0m     dec_outputs , h , c \u001b[39m=\u001b[39m dec_model\u001b[39m.\u001b[39;49mpredict([ empty_target_seq ] \u001b[39m+\u001b[39;49m states_values )\n\u001b[1;32m     11\u001b[0m     sampled_word_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax( dec_outputs[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] )\n\u001b[1;32m     12\u001b[0m     sampled_word \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2211\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2213\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2214\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2217\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2218\u001b[0m         )\n\u001b[0;32m-> 2220\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2221\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2222\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2223\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2224\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2225\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2226\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2227\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2228\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2229\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2230\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2231\u001b[0m )\n\u001b[1;32m   2233\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1581\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1582\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1261\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1263\u001b[0m     x,\n\u001b[1;32m   1264\u001b[0m     y,\n\u001b[1;32m   1265\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1266\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1267\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1268\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1269\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1270\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1271\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1272\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1273\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1274\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1275\u001b[0m )\n\u001b[1;32m   1277\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:347\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m         flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[1;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[0;32m--> 347\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[1;32m    349\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2245\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_map\u001b[39m(\u001b[39mself\u001b[39m, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2213\u001b[0m   \u001b[39m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[1;32m   2214\u001b[0m \n\u001b[1;32m   2215\u001b[0m \u001b[39m  The type signature is:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m   2244\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2245\u001b[0m   \u001b[39mreturn\u001b[39;00m FlatMapDataset(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5484\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m   5482\u001b[0m \u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m   5483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m-> 5484\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m   5485\u001b[0m     map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[1;32m   5486\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[1;32m   5487\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   5488\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5489\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_get_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2602\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   2603\u001b[0m \n\u001b[1;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m   2611\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:333\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    328\u001b[0m first_k_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mslice(indices, [\u001b[39m0\u001b[39m], [num_in_full_batch])\n\u001b[1;32m    329\u001b[0m first_k_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    330\u001b[0m     first_k_indices, [num_full_batches, batch_size]\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 333\u001b[0m flat_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices(first_k_indices)\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partial_batch_size:\n\u001b[1;32m    335\u001b[0m     index_remainder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensors(\n\u001b[1;32m    336\u001b[0m         tf\u001b[39m.\u001b[39mslice(\n\u001b[1;32m    337\u001b[0m             indices, [num_in_full_batch], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partial_batch_size]\n\u001b[1;32m    338\u001b[0m         )\n\u001b[1;32m    339\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:814\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    737\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    738\u001b[0m   \u001b[39m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \n\u001b[1;32m    740\u001b[0m \u001b[39m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m   \u001b[39mreturn\u001b[39;00m TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4724\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4719\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m   4720\u001b[0m   batch_dim\u001b[39m.\u001b[39massert_is_compatible_with(\n\u001b[1;32m   4721\u001b[0m       tensor_shape\u001b[39m.\u001b[39mDimension(\n\u001b[1;32m   4722\u001b[0m           tensor_shape\u001b[39m.\u001b[39mdimension_value(t\u001b[39m.\u001b[39mget_shape()[\u001b[39m0\u001b[39m])))\n\u001b[0;32m-> 4724\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mtensor_slice_dataset(\n\u001b[1;32m   4725\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensors,\n\u001b[1;32m   4726\u001b[0m     output_shapes\u001b[39m=\u001b[39;49mstructure\u001b[39m.\u001b[39;49mget_flat_tensor_shapes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_structure),\n\u001b[1;32m   4727\u001b[0m     is_files\u001b[39m=\u001b[39;49mis_files,\n\u001b[1;32m   4728\u001b[0m     metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metadata\u001b[39m.\u001b[39;49mSerializeToString())\n\u001b[1;32m   4729\u001b[0m \u001b[39msuper\u001b[39m(TensorSliceDataset, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:7884\u001b[0m, in \u001b[0;36mtensor_slice_dataset\u001b[0;34m(components, output_shapes, is_files, metadata, replicate_on_split, name)\u001b[0m\n\u001b[1;32m   7882\u001b[0m   replicate_on_split \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   7883\u001b[0m replicate_on_split \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(replicate_on_split, \u001b[39m\"\u001b[39m\u001b[39mreplicate_on_split\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7884\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   7885\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mTensorSliceDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, components\u001b[39m=\u001b[39;49mcomponents,\n\u001b[1;32m   7886\u001b[0m                             output_shapes\u001b[39m=\u001b[39;49moutput_shapes, is_files\u001b[39m=\u001b[39;49mis_files,\n\u001b[1;32m   7887\u001b[0m                             metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m   7888\u001b[0m                             replicate_on_split\u001b[39m=\u001b[39;49mreplicate_on_split,\n\u001b[1;32m   7889\u001b[0m                             name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   7890\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   7891\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[1;32m   3801\u001b[0m       node_def,\n\u001b[1;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:2086\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2084\u001b[0m   input_types \u001b[39m=\u001b[39m [i\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inputs]\n\u001b[1;32m   2085\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2086\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39;49m(\n\u001b[1;32m   2087\u001b[0m       x\u001b[39m.\u001b[39;49mis_compatible_with(i\u001b[39m.\u001b[39;49mdtype) \u001b[39mfor\u001b[39;49;00m i, x \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(inputs, input_types)):\n\u001b[1;32m   2088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIn op \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, input types (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) are not compatible \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2089\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mwith expected types (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   2090\u001b[0m                     (node_def\u001b[39m.\u001b[39mname, [i\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inputs], input_types))\n\u001b[1;32m   2092\u001b[0m \u001b[39m# Build the list of control inputs.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:2087\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2084\u001b[0m   input_types \u001b[39m=\u001b[39m [i\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inputs]\n\u001b[1;32m   2085\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2086\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m-> 2087\u001b[0m       x\u001b[39m.\u001b[39;49mis_compatible_with(i\u001b[39m.\u001b[39;49mdtype) \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(inputs, input_types)):\n\u001b[1;32m   2088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIn op \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, input types (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) are not compatible \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2089\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mwith expected types (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   2090\u001b[0m                     (node_def\u001b[39m.\u001b[39mname, [i\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inputs], input_types))\n\u001b[1;32m   2092\u001b[0m \u001b[39m# Build the list of control inputs.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    #empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
